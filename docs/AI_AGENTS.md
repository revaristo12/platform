# ü§ñ Arquitetura dos Agentes de IA

Este documento descreve a arquitetura e funcionamento dos agentes de IA da plataforma.

---

## üìã Vis√£o Geral

O sistema possui dois agentes principais que trabalham em conjunto:

1. **Agente de Transcri√ß√£o** - Converte √°udio em texto
2. **Agente de An√°lise** - Analisa o texto e gera insights

---

## üéôÔ∏è Agente de Transcri√ß√£o

### Responsabilidades

- Captura √°udio em tempo real das reuni√µes
- Transcreve √°udio para texto usando Whisper
- Identifica falantes (diariza√ß√£o)
- Armazena transcri√ß√µes com timestamps

### Fluxo de Funcionamento

```
[√Åudio WebRTC] 
    ‚Üì
[Captura Stream]
    ‚Üì
[Buffer de √Åudio (chunks)]
    ‚Üì
[Whisper API/Local]
    ‚Üì
[Texto Transcrito]
    ‚Üì
[Identifica√ß√£o de Falante]
    ‚Üì
[PostgreSQL + Redis]
```

### Implementa√ß√£o Sugerida

**Localiza√ß√£o:** `backend/app/agents/transcription_agent.py`

```python
class TranscriptionAgent:
    """
    Agente respons√°vel por transcri√ß√£o de √°udio
    """
    
    def __init__(self):
        self.whisper_model = whisper.load_model("base")
        self.audio_buffer = []
        self.is_transcribing = False
    
    async def process_audio_chunk(self, audio_data, room_id):
        """
        Processa chunk de √°udio e transcreve
        """
        # 1. Adiciona ao buffer
        self.audio_buffer.append(audio_data)
        
        # 2. Quando buffer est√° cheio (ex: 3 segundos)
        if len(self.audio_buffer) >= CHUNK_SIZE:
            audio_segment = self.concatenate_chunks()
            
            # 3. Envia para Celery task (ass√≠ncrono)
            transcribe_task.delay(
                audio_segment,
                room_id
            )
            
            # 4. Limpa buffer
            self.audio_buffer.clear()
    
    def transcribe(self, audio_path):
        """
        Transcreve √°udio usando Whisper
        """
        result = self.whisper_model.transcribe(
            audio_path,
            language="pt",
            task="transcribe"
        )
        
        return {
            "text": result["text"],
            "segments": result["segments"],
            "language": result["language"]
        }
    
    def identify_speaker(self, audio_segment):
        """
        Identifica falante usando diariza√ß√£o
        (implementar com pyannote.audio)
        """
        pass
```

### Celery Task

**Localiza√ß√£o:** `backend/app/agents/tasks/transcription.py`

```python
@celery_app.task
def transcribe_task(audio_data, room_id):
    """
    Task ass√≠ncrona de transcri√ß√£o
    """
    # 1. Salva √°udio tempor√°rio
    temp_path = save_temp_audio(audio_data)
    
    # 2. Transcreve
    agent = TranscriptionAgent()
    result = agent.transcribe(temp_path)
    
    # 3. Salva no banco
    for segment in result["segments"]:
        Transcription.create(
            room_id=room_id,
            text=segment["text"],
            start_time=segment["start"],
            end_time=segment["end"],
            confidence=segment.get("confidence")
        )
    
    # 4. Notifica via WebSocket
    notify_new_transcription(room_id, result)
    
    # 5. Trigger an√°lise se necess√°rio
    if should_trigger_analysis():
        analysis_task.delay(room_id)
    
    # 6. Limpa arquivo tempor√°rio
    os.remove(temp_path)
```

### Otimiza√ß√µes

1. **Streaming Transcription**
   - Usar buffer circular
   - Transcrever em chunks pequenos (2-3 segundos)
   - Combinar resultados com overlap

2. **Local vs API**
   - Local: Whisper rodando no container (mais lento, sem custo)
   - API: OpenAI Whisper API (mais r√°pido, com custo)
   - Configur√°vel via `.env`

3. **Diariza√ß√£o de Falantes**
   - Usar `pyannote.audio`
   - Treinar modelo customizado se necess√°rio
   - Armazenar embeddings de voz

---

## üß† Agente de An√°lise

### Responsabilidades

- L√™ transcri√ß√µes acumuladas
- Analisa contexto e identifica:
  - Riscos e problemas
  - Decis√µes tomadas
  - Gaps de governan√ßa
  - A√ß√µes necess√°rias
- Gera insights e recomenda√ß√µes
- Avalia n√≠vel de criticidade

### Fluxo de Funcionamento

```
[Transcri√ß√µes acumuladas]
    ‚Üì
[Trigger de An√°lise]
    ‚Üì
[Agrega√ß√£o de Texto]
    ‚Üì
[Prompt Engineering]
    ‚Üì
[Claude/GPT API]
    ‚Üì
[Parsing de Resposta]
    ‚Üì
[Estrutura√ß√£o de Insights]
    ‚Üì
[PostgreSQL + Notifica√ß√µes]
```

### Implementa√ß√£o Sugerida

**Localiza√ß√£o:** `backend/app/agents/analysis_agent.py`

```python
class AnalysisAgent:
    """
    Agente de an√°lise com IA para governan√ßa e crises
    """
    
    def __init__(self):
        self.llm = self.initialize_llm()
        self.system_prompt = self.load_system_prompt()
    
    def initialize_llm(self):
        """
        Inicializa Claude ou GPT
        """
        if settings.USE_CLAUDE:
            from anthropic import Anthropic
            return Anthropic(api_key=settings.ANTHROPIC_API_KEY)
        else:
            from openai import OpenAI
            return OpenAI(api_key=settings.OPENAI_API_KEY)
    
    async def analyze_meeting(self, room_id):
        """
        Analisa reuni√£o completa
        """
        # 1. Busca transcri√ß√µes
        transcriptions = await self.get_transcriptions(room_id)
        
        # 2. Prepara contexto
        context = self.prepare_context(transcriptions)
        
        # 3. Analisa com IA
        analysis = await self.run_analysis(context)
        
        # 4. Estrutura resultados
        structured = self.structure_analysis(analysis)
        
        # 5. Salva no banco
        await self.save_analysis(room_id, structured)
        
        # 6. Envia notifica√ß√µes se necess√°rio
        if structured["risk_level"] in ["high", "critical"]:
            await self.notify_stakeholders(room_id, structured)
        
        return structured
    
    def load_system_prompt(self):
        """
        Carrega prompt do sistema
        """
        return """
        Voc√™ √© um especialista em gest√£o de crises, governan√ßa corporativa 
        e an√°lise de riscos empresariais. Sua fun√ß√£o √© analisar transcri√ß√µes 
        de reuni√µes e identificar:
        
        1. RISCOS E PROBLEMAS
           - Identificar riscos mencionados
           - Avaliar gravidade (baixa, m√©dia, alta, cr√≠tica)
           - Classificar tipo (operacional, financeiro, reputacional, etc)
        
        2. DECIS√ïES TOMADAS
           - Listar decis√µes expl√≠citas
           - Identificar respons√°veis
           - Notar prazos mencionados
        
        3. GAPS DE GOVERNAN√áA
           - Processos inexistentes ou falhos
           - Falta de controles
           - Problemas de comunica√ß√£o
        
        4. A√á√ïES NECESS√ÅRIAS
           - Action items identificados
           - Respons√°veis sugeridos
           - Prioriza√ß√£o
        
        5. RECOMENDA√á√ïES
           - Planos de mitiga√ß√£o
           - Melhorias de processo
           - Controles a implementar
        
        Forne√ßa a an√°lise em formato JSON estruturado.
        """
    
    def prepare_context(self, transcriptions):
        """
        Prepara contexto para an√°lise
        """
        # Agrupa por falante
        speakers_text = {}
        for trans in transcriptions:
            speaker = trans.speaker_label or "Unknown"
            if speaker not in speakers_text:
                speakers_text[speaker] = []
            speakers_text[speaker].append(trans.text)
        
        # Formata contexto
        context = "=== TRANSCRI√á√ÉO DA REUNI√ÉO ===\n\n"
        for speaker, texts in speakers_text.items():
            context += f"{speaker}:\n"
            context += "\n".join(texts)
            context += "\n\n"
        
        return context
    
    async def run_analysis(self, context):
        """
        Executa an√°lise com LLM
        """
        if isinstance(self.llm, Anthropic):
            # Claude
            response = self.llm.messages.create(
                model="claude-3-opus-20240229",
                max_tokens=4096,
                system=self.system_prompt,
                messages=[
                    {
                        "role": "user",
                        "content": f"{context}\n\nAnalise esta reuni√£o:"
                    }
                ]
            )
            return response.content[0].text
        else:
            # GPT
            response = self.llm.chat.completions.create(
                model="gpt-4-turbo-preview",
                messages=[
                    {"role": "system", "content": self.system_prompt},
                    {"role": "user", "content": f"{context}\n\nAnalise:"}
                ]
            )
            return response.choices[0].message.content
    
    def structure_analysis(self, raw_analysis):
        """
        Estrutura an√°lise em formato padr√£o
        """
        # Parse JSON da resposta
        analysis = json.loads(raw_analysis)
        
        return {
            "risks": analysis.get("risks", []),
            "decisions": analysis.get("decisions", []),
            "governance_gaps": analysis.get("governance_gaps", []),
            "action_items": analysis.get("action_items", []),
            "recommendations": analysis.get("recommendations", []),
            "risk_level": self.calculate_risk_level(analysis),
            "summary": analysis.get("summary", ""),
            "key_topics": analysis.get("key_topics", [])
        }
```

### Celery Task

**Localiza√ß√£o:** `backend/app/agents/tasks/analysis.py`

```python
@celery_app.task
def analysis_task(room_id):
    """
    Task ass√≠ncrona de an√°lise
    """
    agent = AnalysisAgent()
    
    try:
        # Executa an√°lise
        result = asyncio.run(
            agent.analyze_meeting(room_id)
        )
        
        # Notifica usu√°rios via WebSocket
        notify_new_analysis(room_id, result)
        
        return result
        
    except Exception as e:
        logger.error(f"Error in analysis: {e}")
        raise
```

### Triggers de An√°lise

A an√°lise pode ser disparada por:

1. **Intervalo de Tempo** (ex: a cada 5 minutos)
2. **N√∫mero de Palavras** (ex: a cada 500 palavras)
3. **Palavras-chave** (ex: "crise", "risco", "problema")
4. **Manual** (bot√£o no frontend)
5. **Fim da Reuni√£o**

```python
def should_trigger_analysis(room_id):
    """
    Decide se deve disparar an√°lise
    """
    last_analysis = get_last_analysis(room_id)
    new_transcriptions = get_transcriptions_since(
        room_id, 
        last_analysis.created_at
    )
    
    # Trigger por palavras
    word_count = sum(len(t.text.split()) for t in new_transcriptions)
    if word_count >= 500:
        return True
    
    # Trigger por tempo
    time_since = datetime.now() - last_analysis.created_at
    if time_since.total_seconds() >= 300:  # 5 minutos
        return True
    
    # Trigger por palavras-chave
    keywords = ["crise", "risco", "urgente", "problema cr√≠tico"]
    text = " ".join(t.text for t in new_transcriptions).lower()
    if any(kw in text for kw in keywords):
        return True
    
    return False
```

---

## üîÑ Integra√ß√£o dos Agentes

### Fluxo Completo

```
[Usu√°rio fala na reuni√£o]
           ‚Üì
[WebRTC Stream ‚Üí Backend]
           ‚Üì
[TranscriptionAgent.process_audio_chunk()]
           ‚Üì
[Celery: transcribe_task]
           ‚Üì
[Salva no DB + Notifica WebSocket]
           ‚Üì
[Verifica: should_trigger_analysis()?]
           ‚Üì (se sim)
[Celery: analysis_task]
           ‚Üì
[AnalysisAgent.analyze_meeting()]
           ‚Üì
[Salva insights + Notifica]
           ‚Üì
[Dashboard atualizado em tempo real]
```

---

## üéõÔ∏è Configura√ß√µes

### `.env`

```env
# Transcri√ß√£o
WHISPER_MODEL=base              # tiny, base, small, medium, large
TRANSCRIPTION_LANGUAGE=pt
ENABLE_SPEAKER_DIARIZATION=True
MIN_SPEAKERS=1
MAX_SPEAKERS=10

# An√°lise
AI_ANALYSIS_ENABLED=True
AI_ANALYSIS_INTERVAL=300        # segundos
AI_ANALYSIS_MIN_WORDS=100
USE_CLAUDE=True                 # True para Claude, False para GPT
CLAUDE_MODEL=claude-3-opus-20240229
OPENAI_MODEL=gpt-4-turbo-preview
```

---

## üìä Exemplos de Output

### Transcri√ß√£o

```json
{
  "id": "uuid",
  "room_id": "uuid",
  "speaker_label": "Speaker_1",
  "text": "Estamos enfrentando um problema cr√≠tico...",
  "confidence": 0.95,
  "start_time": 125.3,
  "end_time": 128.7,
  "created_at": "2024-01-15T10:30:00Z"
}
```

### An√°lise

```json
{
  "id": "uuid",
  "room_id": "uuid",
  "risk_level": "high",
  "summary": "Reuni√£o identificou crise operacional...",
  "risks": [
    {
      "description": "Sistema de pagamentos inst√°vel",
      "severity": "high",
      "type": "operational",
      "mentioned_at": "10:25"
    }
  ],
  "decisions": [
    {
      "decision": "Contratar empresa terceirizada",
      "responsible": "Jo√£o Silva",
      "deadline": "2024-01-20"
    }
  ],
  "governance_gaps": [
    "Falta de processo de backup",
    "Comunica√ß√£o inadequada entre times"
  ],
  "action_items": [
    {
      "action": "Implementar monitoramento 24/7",
      "priority": "critical",
      "responsible": "TI",
      "deadline": "Imediato"
    }
  ],
  "recommendations": [
    "Estabelecer comit√™ de crise",
    "Criar plano de conting√™ncia",
    "Revisar SLAs com fornecedores"
  ],
  "created_at": "2024-01-15T10:35:00Z"
}
```

---

## üöÄ Pr√≥ximos Passos

1. Implementar `TranscriptionAgent`
2. Implementar `AnalysisAgent`
3. Criar Celery tasks
4. Testar com √°udio real
5. Ajustar prompts para melhor qualidade
6. Implementar diariza√ß√£o de falantes
7. Criar dashboard de visualiza√ß√£o

---

**Documenta√ß√£o t√©cnica dos agentes de IA - Meeting AI Platform**
